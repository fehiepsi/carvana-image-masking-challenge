{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:40.812958Z",
     "start_time": "2017-09-22T05:00:40.799198Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.145148Z",
     "start_time": "2017-09-22T05:00:40.817093Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.316345Z",
     "start_time": "2017-09-22T05:00:41.146579Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.348312Z",
     "start_time": "2017-09-22T05:00:41.317752Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'train_path': '../data/train4320/',\n",
    "    'train_masks_path': '../data/train4320_masks/',\n",
    "    'val_path': '../data/val768/',\n",
    "    'val_masks_path': '../data/val768_masks/',\n",
    "    'test_path': '../data/test_hq/',\n",
    "    'output_path': '../intermediate/output_tn/',\n",
    "    'split_data': False,\n",
    "    'batch_size': 3,\n",
    "    'log_every': 100,\n",
    "    'train': True,\n",
    "    'model_name': '',\n",
    "    'test': False,\n",
    "    'seed': 20170922,\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "args.intermediate_path = os.path.join('../intermediate/',\n",
    "                                      str(args.seed), 'dn')\n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.mkdir(args.intermediate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.416082Z",
     "start_time": "2017-09-22T05:00:41.349430Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if args.split_data:\n",
    "    # !mogrify -format png *.gif\n",
    "    if not os.path.isdir(args.train_path):\n",
    "        os.mkdir(args.train_path)\n",
    "    if not os.path.isdir(args.train_masks_path):\n",
    "        os.mkdir(args.train_masks_path)\n",
    "    if not os.path.isdir(args.val_path):\n",
    "        os.mkdir(args.val_path)\n",
    "    if not os.path.isdir(args.val_masks_path):\n",
    "        os.mkdir(args.val_masks_path)\n",
    "    files = sorted([x.split('/')[-1]\n",
    "                    for x in glob.glob('../data/train_hq/*.jpg')])\n",
    "    random.seed(args.seed)\n",
    "    random.shuffle(files)\n",
    "    for filename in files[:4320]:\n",
    "        image = cv2.imread('../data/train_hq/' + filename)\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        cv2.imwrite(os.path.join(args.train_path, filename), image)\n",
    "        mask_filename = '../data/train_masks/'+filename.replace('.jpg',\n",
    "                                                                '_mask.png')\n",
    "        shutil.copy2(mask_filename, args.train_masks_path)\n",
    "    for filename in files[4320:]:\n",
    "        image = cv2.imread('../data/train_hq/' + filename)\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        cv2.imwrite(os.path.join(args.val_path, filename), image)\n",
    "        mask_filename = '../data/train_masks/'+filename.replace('.jpg',\n",
    "                                                                '_mask.png')\n",
    "        shutil.copy2(mask_filename, args.val_masks_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.486027Z",
     "start_time": "2017-09-22T05:00:41.417259Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBnRelu2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        padding = kernel_size//2 * dilation\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              dilation=dilation, padding=padding, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            o = self.bn(o)\n",
    "        return F.relu(o, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.519804Z",
     "start_time": "2017-09-22T05:00:41.491101Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            ConvBnRelu2d(in_channels, out_channels, kernel_size),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size, dilation=2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.encode(x)\n",
    "        o = F.max_pool2d(e, kernel_size=2, stride=2)\n",
    "        return e, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.595825Z",
     "start_time": "2017-09-22T05:00:41.523188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, e_channels, in_channels, out_channels, kernel_size=3):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(in_channels, in_channels,\n",
    "                                           kernel_size=2, stride=2)\n",
    "        self.decode = nn.Sequential(\n",
    "            ConvBnRelu2d(e_channels+in_channels, out_channels, kernel_size),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size))\n",
    "\n",
    "    def forward(self, e, x):\n",
    "        N,C,H,W = e.size()\n",
    "        x = self.upsample(x)\n",
    "#        x = F.upsample(x, size=(H,W), mode='bilinear')\n",
    "        x = torch.cat([e, x], dim=1)\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.687553Z",
     "start_time": "2017-09-22T05:00:41.600736Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UNet1024(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_shape):\n",
    "        super(UNet1024, self).__init__()\n",
    "        C,H,W = in_shape\n",
    "\n",
    "        # 1024\n",
    "        self.down1 = StackEncoder(  C,  24)  # 512\n",
    "        self.down2 = StackEncoder( 24,  64)  # 256\n",
    "        self.down3 = StackEncoder( 64, 128)  # 128\n",
    "        self.down4 = StackEncoder(128, 256)  # 64\n",
    "        self.down5 = StackEncoder(256, 512)  # 32\n",
    "        self.down6 = StackEncoder(512, 768)  # 16\n",
    "\n",
    "        self.center = ConvBnRelu2d(768, 768)\n",
    "\n",
    "        # 16\n",
    "        self.up6 = StackDecoder(768, 768, 512)  # 32\n",
    "        self.up5 = StackDecoder(512, 512, 256)  # 64\n",
    "        self.up4 = StackDecoder(256, 256, 128)  # 128\n",
    "        self.up3 = StackDecoder(128, 128,  64)  # 256\n",
    "        self.up2 = StackDecoder( 64,  64,  24)  # 512\n",
    "        self.up1 = StackDecoder( 24,  24,  24)  # 1024\n",
    "        \n",
    "        self.mask = nn.Conv2d(24, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1, o = self.down1(x)\n",
    "        e2, o = self.down2(o)\n",
    "        e3, o = self.down3(o)\n",
    "        e4, o = self.down4(o)\n",
    "        e5, o = self.down5(o)\n",
    "        e6, o = self.down6(o)\n",
    "\n",
    "        o = self.center(o)\n",
    "        \n",
    "        o = self.up6(e6, o)\n",
    "        o = self.up5(e5, o)\n",
    "        o = self.up4(e4, o)\n",
    "        o = self.up3(e3, o)\n",
    "        o = self.up2(e2, o)\n",
    "        o = self.up1(e1, o)\n",
    "\n",
    "        o = self.mask(o)\n",
    "        o = F.upsample(o, size=(1280,1918), mode='bilinear')\n",
    "        return torch.squeeze(o, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.760815Z",
     "start_time": "2017-09-22T05:00:41.688665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_score(probs, target, weight=None, use_mask=True, threshold=0.5):\n",
    "    if use_mask:\n",
    "        probs = (probs > threshold).float()\n",
    "    N     = target.size(0)\n",
    "    if weight is None:\n",
    "        w = Variable(torch.ones(target.size()).cuda()).view(N, -1)\n",
    "    else:\n",
    "        w = weight.view(N, -1)\n",
    "    w2    = w*w\n",
    "    m1    = probs.view(N, -1)\n",
    "    m2    = target.view(N, -1)\n",
    "    score = (2*(w2*m1*m2).sum(dim=1) + 1) / ((w2*m1).sum(dim=1) + (w2*m2).sum(dim=1) + 1)\n",
    "    \n",
    "    return score.sum()/N\n",
    "\n",
    "\n",
    "def dice_loss(logits, target, weight=None):\n",
    "    probs = F.sigmoid(logits)\n",
    "    loss  = 1 - dice_score(probs, target, weight, use_mask=False)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def criterion(logits, target):\n",
    "    N,H,W = target.size()\n",
    "    a = F.avg_pool2d(target, kernel_size=41, stride=1, padding=20)\n",
    "    boundary = (a.ge(0.01) * a.le(0.99)).float()\n",
    "    weight = Variable(torch.ones(a.size()).cuda())\n",
    "    w0 = weight.sum()\n",
    "    weight = weight + 2*boundary\n",
    "    w1 = weight.sum()\n",
    "    weight = weight*w0/w1\n",
    "        \n",
    "    return (F.binary_cross_entropy_with_logits(logits, target, weight),\n",
    "            dice_loss(logits, target, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.829549Z",
     "start_time": "2017-09-22T05:00:41.761926Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    image = image.transpose((2,0,1)).astype(np.float32)  # HWC -> CHW\n",
    "    tensor = torch.from_numpy(image)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def label_to_tensor(label, threshold=0.5):\n",
    "    label  = (label>threshold).astype(np.float32)\n",
    "    tensor = torch.from_numpy(label)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.927318Z",
     "start_time": "2017-09-22T05:00:41.833626Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_path, mask_path='', transform=[], mode='train'):\n",
    "        super(CarDataset, self).__init__()\n",
    "        self.img_names = sorted([x.split('/')[-1] for x in glob.glob(image_path + '/*.jpg')])\n",
    "        self.img_path  = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.transform = transform\n",
    "        self.mode      = mode\n",
    "\n",
    "    def get_image(self, index):\n",
    "        name  = self.img_names[index]\n",
    "        file  = os.path.join(self.img_path, name)\n",
    "        img   = cv2.imread(file)\n",
    "        image = img / 255\n",
    "        return image, name\n",
    "    \n",
    "    def get_label(self, name):\n",
    "        name = name.replace('.jpg', '_mask.png')\n",
    "        file = os.path.join(self.mask_path, name)\n",
    "        mask = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        label = mask / 255\n",
    "        return label\n",
    "\n",
    "    def get_train_item(self, index):\n",
    "        image, name = self.get_image(index)\n",
    "        label = self.get_label(name)\n",
    "        image = image_to_tensor(image)\n",
    "        label = label_to_tensor(label)\n",
    "        return image, label\n",
    "\n",
    "    def get_test_item(self, index):\n",
    "        image, _ = self.get_image(index)\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        image = image_to_tensor(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            return self.get_train_item(index)\n",
    "        elif self.mode == 'test':\n",
    "            return self.get_test_item(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:41.987744Z",
     "start_time": "2017-09-22T05:00:41.928279Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer):\n",
    "    num_grad_acc = 16 // args.batch_size\n",
    "    model.train()\n",
    "    train_bce_loss = 0\n",
    "    train_score = 0\n",
    "    init_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    for i, (inputt, target) in enumerate(train_loader, 1):\n",
    "        inputt = inputt.cuda()\n",
    "        target = target.cuda()\n",
    "        inputt = Variable(inputt)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        output = model(inputt)\n",
    "        bce_loss, dice_loss = criterion(output, target)\n",
    "        loss = bce_loss + dice_loss\n",
    "        loss.backward()\n",
    "        if i % num_grad_acc == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        train_bce_loss += bce_loss.data[0] * inputt.size(0)\n",
    "        train_score += (1-dice_loss).data[0] * inputt.size(0)\n",
    "        if i % args.log_every == 0:\n",
    "            print(\"   % Time: {:4.0f}s | Batch: {:4} | \"\n",
    "                  \"Train bce loss: {:.5f} | Train score: {:.5f}\"\n",
    "                  .format(time.time()-init_time, i,\n",
    "                          bce_loss.data[0], (1-dice_loss).data[0]))\n",
    "    return (train_bce_loss / len(train_loader.dataset),\n",
    "            train_score / len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.066932Z",
     "start_time": "2017-09-22T05:00:41.988775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model):\n",
    "    model.eval()\n",
    "    val_score = 0\n",
    "    for i, (inputt, target) in enumerate(val_loader, 1):\n",
    "        inputt = inputt.cuda()\n",
    "        target = target.cuda()\n",
    "        inputt = Variable(inputt, volatile=True)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        output = model(inputt)\n",
    "        score = dice_score(F.sigmoid(output), target)\n",
    "        val_score += score.data[0] * inputt.size(0)\n",
    "    return val_score / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.108414Z",
     "start_time": "2017-09-22T05:00:42.071278Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, epoch, score):\n",
    "    model_file = os.path.join(args.intermediate_path,\n",
    "                              \"model_{}_epoch{}_score{:.5f}.pth\"\n",
    "                              .format(args.seed, epoch, score))\n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.162430Z",
     "start_time": "2017-09-22T05:00:42.109830Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model, model_name):\n",
    "    model_path = os.path.join(args.intermediate_path, model_name)\n",
    "    assert os.path.isfile(model_path), 'Error: no model found!'\n",
    "    model_state = torch.load(model_path)\n",
    "    model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.225597Z",
     "start_time": "2017-09-22T05:00:42.167232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rle_encode(mask_image):\n",
    "    pixels = mask_image.flatten()\n",
    "    # We avoid issues with '1' at the start or end (at the corners of \n",
    "    # the original image) by setting those pixels to '0' explicitly.\n",
    "    # We do not expect these to be non-zero for an accurate mask, \n",
    "    # so this should not harm the score.\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.274302Z",
     "start_time": "2017-09-22T05:00:42.229935Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_loader, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    init_time = time.time()\n",
    "    list_rle = []\n",
    "    c = 0\n",
    "    for i, imgs in enumerate(test_loader, 1):\n",
    "        imgs = imgs.cuda()\n",
    "        imgs = Variable(imgs, volatile=True)\n",
    "        outputs = model(imgs)\n",
    "        for j in range(outputs.size(0)):\n",
    "            c += 1\n",
    "            image = outputs[j, :, :].data.cpu().numpy()\n",
    "            cv2.imwrite(os.path.join(args.output_path, str(c)+'.jpg'), image)\n",
    "#        outputs = outputs > threshold\n",
    "#        for j in range(outputs.size(0)):\n",
    "#            rle = rle_encode(outputs[j, :, :].data.cpu().numpy())\n",
    "#            list_rle.append(' '.join(str(x) for x in rle))\n",
    "            \n",
    "        if i % args.log_every == 0:\n",
    "            print(\"   % Time: {:4.0f}s | Image: {:6d} / {}\"\n",
    "                  .format(time.time()-init_time, i*args.batch_size,\n",
    "                          len(test_loader.dataset)))\n",
    "    return list_rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.346095Z",
     "start_time": "2017-09-22T05:00:42.275670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CarDataset(args.train_path, args.train_masks_path,\n",
    "                           transform=[], mode='train')\n",
    "train_loader  = DataLoader(train_dataset, args.batch_size, shuffle=True, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T05:00:42.381345Z",
     "start_time": "2017-09-22T05:00:42.347970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_dataset = CarDataset(args.val_path, args.val_masks_path,\n",
    "                         transform=[], mode='train')\n",
    "val_loader  = DataLoader(val_dataset, args.batch_size, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-22T05:00:42.339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = UNet1024((3, 1024, 1024))\n",
    "model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,\n",
    "                      weight_decay=0.0005)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-22T05:00:42.344Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.57158 | Train score: 0.39764\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.47062 | Train score: 0.47180\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.35740 | Train score: 0.57997\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.27814 | Train score: 0.63745\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.16698 | Train score: 0.73111\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.15595 | Train score: 0.78287\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.09398 | Train score: 0.85166\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.08924 | Train score: 0.85650\n",
      "   % Time:  705s | Batch:  900 | Train bce loss: 0.06346 | Train score: 0.90608\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.04773 | Train score: 0.92041\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.08883 | Train score: 0.90012\n",
      "   % Time:  940s | Batch: 1200 | Train bce loss: 0.04024 | Train score: 0.92481\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.05771 | Train score: 0.91909\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.04016 | Train score: 0.93523\n",
      "==========\n",
      "   % Time: 1180s | Epoch:    1 | Train bce loss: 0.19768 | Train score: 0.76297 | Val score: 0.98609\n",
      "==========\n",
      "=> EPOCH 2 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.04085 | Train score: 0.93993\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.05726 | Train score: 0.93853\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.04628 | Train score: 0.93849\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.04328 | Train score: 0.94584\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.03197 | Train score: 0.94801\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.04512 | Train score: 0.93439\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.02904 | Train score: 0.95190\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.02941 | Train score: 0.95421\n",
      "   % Time:  705s | Batch:  900 | Train bce loss: 0.05728 | Train score: 0.93473\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.03028 | Train score: 0.95019\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.03533 | Train score: 0.94970\n",
      "   % Time:  940s | Batch: 1200 | Train bce loss: 0.02177 | Train score: 0.96347\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.03325 | Train score: 0.95434\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.04261 | Train score: 0.95128\n",
      "==========\n",
      "   % Time: 1180s | Epoch:    2 | Train bce loss: 0.03856 | Train score: 0.94605 | Val score: 0.99090\n",
      "==========\n",
      "=> EPOCH 3 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.05459 | Train score: 0.93584\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.02107 | Train score: 0.96913\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.03842 | Train score: 0.94920\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01983 | Train score: 0.96268\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.02329 | Train score: 0.96073\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.02338 | Train score: 0.96689\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.02679 | Train score: 0.96221\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.02843 | Train score: 0.96446\n",
      "   % Time:  705s | Batch:  900 | Train bce loss: 0.03321 | Train score: 0.95873\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.02002 | Train score: 0.96604\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.03302 | Train score: 0.95320\n",
      "   % Time:  940s | Batch: 1200 | Train bce loss: 0.02142 | Train score: 0.96092\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.02766 | Train score: 0.96137\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01824 | Train score: 0.96952\n",
      "==========\n",
      "   % Time: 1181s | Epoch:    3 | Train bce loss: 0.02804 | Train score: 0.96092 | Val score: 0.99229\n",
      "==========\n",
      "=> EPOCH 4 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.02479 | Train score: 0.96800\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01613 | Train score: 0.97317\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01649 | Train score: 0.97227\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.02426 | Train score: 0.96169\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01404 | Train score: 0.96931\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.02534 | Train score: 0.96710\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01834 | Train score: 0.96923\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.04397 | Train score: 0.96031\n",
      "   % Time:  705s | Batch:  900 | Train bce loss: 0.01466 | Train score: 0.97566\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.02868 | Train score: 0.96493\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.02576 | Train score: 0.96200\n",
      "   % Time:  940s | Batch: 1200 | Train bce loss: 0.01605 | Train score: 0.97077\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.03950 | Train score: 0.96110\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.02217 | Train score: 0.95922\n",
      "==========\n",
      "   % Time: 1180s | Epoch:    4 | Train bce loss: 0.02342 | Train score: 0.96719 | Val score: 0.99231\n",
      "==========\n",
      "=> EPOCH 5 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.03059 | Train score: 0.96817\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01534 | Train score: 0.97237\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.02726 | Train score: 0.96889\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.02788 | Train score: 0.96464\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.02185 | Train score: 0.96830\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01304 | Train score: 0.97689\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01600 | Train score: 0.97223\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.02547 | Train score: 0.97062\n",
      "   % Time:  705s | Batch:  900 | Train bce loss: 0.01959 | Train score: 0.97465\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.02690 | Train score: 0.95694\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01550 | Train score: 0.97094\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01648 | Train score: 0.97433\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01333 | Train score: 0.97822\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.03819 | Train score: 0.96582\n",
      "==========\n",
      "   % Time: 1181s | Epoch:    5 | Train bce loss: 0.02033 | Train score: 0.97119 | Val score: 0.99422\n",
      "==========\n",
      "=> EPOCH 6 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01465 | Train score: 0.97552\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01405 | Train score: 0.97596\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01700 | Train score: 0.97470\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01807 | Train score: 0.97409\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01294 | Train score: 0.97489\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01864 | Train score: 0.97349\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01531 | Train score: 0.97855\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01775 | Train score: 0.97367\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01568 | Train score: 0.97833\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.03358 | Train score: 0.96540\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.02135 | Train score: 0.97151\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.02716 | Train score: 0.96691\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.03135 | Train score: 0.96655\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.02129 | Train score: 0.97215\n",
      "==========\n",
      "   % Time: 1181s | Epoch:    6 | Train bce loss: 0.01842 | Train score: 0.97361 | Val score: 0.98237\n",
      "==========\n",
      "=> EPOCH 7 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01316 | Train score: 0.97420\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01727 | Train score: 0.97667\n",
      "   % Time:  236s | Batch:  300 | Train bce loss: 0.01690 | Train score: 0.97565\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01291 | Train score: 0.97317\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01845 | Train score: 0.97540\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01071 | Train score: 0.97910\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.02075 | Train score: 0.97691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01441 | Train score: 0.97709\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01486 | Train score: 0.97724\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01429 | Train score: 0.97784\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.02073 | Train score: 0.97346\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01118 | Train score: 0.97677\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.02468 | Train score: 0.97287\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01443 | Train score: 0.97707\n",
      "==========\n",
      "   % Time: 1181s | Epoch:    7 | Train bce loss: 0.01673 | Train score: 0.97575 | Val score: 0.99472\n",
      "==========\n",
      "=> EPOCH 8 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.00878 | Train score: 0.98361\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01822 | Train score: 0.97574\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01959 | Train score: 0.97523\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01938 | Train score: 0.97047\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01352 | Train score: 0.97924\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01846 | Train score: 0.97220\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01697 | Train score: 0.97731\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01253 | Train score: 0.97964\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01353 | Train score: 0.98092\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01635 | Train score: 0.97881\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01324 | Train score: 0.97670\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01788 | Train score: 0.97578\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01893 | Train score: 0.97868\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01706 | Train score: 0.97566\n",
      "==========\n",
      "   % Time: 1181s | Epoch:    8 | Train bce loss: 0.01563 | Train score: 0.97720 | Val score: 0.99529\n",
      "==========\n",
      "=> EPOCH 9 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01463 | Train score: 0.97695\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01203 | Train score: 0.97872\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01136 | Train score: 0.98100\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01234 | Train score: 0.97963\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01906 | Train score: 0.97824\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01327 | Train score: 0.97659\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01424 | Train score: 0.98090\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01016 | Train score: 0.98080\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01752 | Train score: 0.97880\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01567 | Train score: 0.98057\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01257 | Train score: 0.97762\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.02244 | Train score: 0.97394\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01367 | Train score: 0.97993\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01701 | Train score: 0.97722\n",
      "==========\n",
      "   % Time: 1181s | Epoch:    9 | Train bce loss: 0.01488 | Train score: 0.97821 | Val score: 0.99547\n",
      "==========\n",
      "=> EPOCH 10 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01342 | Train score: 0.97990\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01453 | Train score: 0.98041\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01071 | Train score: 0.98239\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01428 | Train score: 0.97861\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01311 | Train score: 0.97985\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01274 | Train score: 0.98078\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01725 | Train score: 0.97617\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01317 | Train score: 0.98002\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01141 | Train score: 0.98229\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.02649 | Train score: 0.97067\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01649 | Train score: 0.97406\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01126 | Train score: 0.98023\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.02187 | Train score: 0.97465\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01318 | Train score: 0.97954\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   10 | Train bce loss: 0.01433 | Train score: 0.97894 | Val score: 0.99534\n",
      "==========\n",
      "=> EPOCH 11 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01496 | Train score: 0.97681\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01401 | Train score: 0.97718\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01264 | Train score: 0.98083\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.00864 | Train score: 0.98440\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01236 | Train score: 0.98014\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01636 | Train score: 0.97713\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.00979 | Train score: 0.98353\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01455 | Train score: 0.97936\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01588 | Train score: 0.97851\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01342 | Train score: 0.98089\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.00962 | Train score: 0.98234\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.00884 | Train score: 0.98137\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01795 | Train score: 0.97827\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01629 | Train score: 0.98086\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   11 | Train bce loss: 0.01365 | Train score: 0.97979 | Val score: 0.99569\n",
      "==========\n",
      "=> EPOCH 12 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.00914 | Train score: 0.98393\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01362 | Train score: 0.97805\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.00985 | Train score: 0.98287\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01080 | Train score: 0.98293\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01030 | Train score: 0.98223\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01140 | Train score: 0.98311\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01260 | Train score: 0.97765\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.00934 | Train score: 0.98385\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01581 | Train score: 0.97906\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.00950 | Train score: 0.98320\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01325 | Train score: 0.97947\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.00962 | Train score: 0.98310\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01362 | Train score: 0.98025\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01399 | Train score: 0.98161\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   12 | Train bce loss: 0.01315 | Train score: 0.98046 | Val score: 0.91923\n",
      "==========\n",
      "=> EPOCH 13 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.02167 | Train score: 0.97346\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.00997 | Train score: 0.98282\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01711 | Train score: 0.97781\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01284 | Train score: 0.98100\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01865 | Train score: 0.97919\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01626 | Train score: 0.97842\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01140 | Train score: 0.98133\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.00867 | Train score: 0.98467\n",
      "   % Time:  705s | Batch:  900 | Train bce loss: 0.00799 | Train score: 0.98402\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01144 | Train score: 0.98209\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.00830 | Train score: 0.98440\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01144 | Train score: 0.98160\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01520 | Train score: 0.97648\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01169 | Train score: 0.98153\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   13 | Train bce loss: 0.01280 | Train score: 0.98093 | Val score: 0.99562\n",
      "==========\n",
      "=> EPOCH 14 with lr [0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01342 | Train score: 0.98068\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01032 | Train score: 0.98433\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01117 | Train score: 0.97816\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01227 | Train score: 0.98168\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.00894 | Train score: 0.98206\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.02059 | Train score: 0.97186\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01087 | Train score: 0.98055\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01204 | Train score: 0.98230\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01136 | Train score: 0.98324\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.00965 | Train score: 0.98368\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01009 | Train score: 0.98225\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01041 | Train score: 0.98358\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01271 | Train score: 0.98188\n",
      "   % Time: 1098s | Batch: 1400 | Train bce loss: 0.01018 | Train score: 0.98403\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   14 | Train bce loss: 0.01241 | Train score: 0.98147 | Val score: 0.97231\n",
      "==========\n",
      "=> EPOCH 15 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.00933 | Train score: 0.98336\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01083 | Train score: 0.98192\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.00860 | Train score: 0.98490\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01485 | Train score: 0.98055\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01514 | Train score: 0.98061\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.00956 | Train score: 0.98477\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01197 | Train score: 0.98279\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01335 | Train score: 0.98190\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01120 | Train score: 0.98338\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01413 | Train score: 0.98029\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.00993 | Train score: 0.98194\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01115 | Train score: 0.98259\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01107 | Train score: 0.98155\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01242 | Train score: 0.98081\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   15 | Train bce loss: 0.01210 | Train score: 0.98185 | Val score: 0.99262\n",
      "==========\n",
      "=> EPOCH 16 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.00805 | Train score: 0.98547\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01451 | Train score: 0.98096\n",
      "   % Time:  236s | Batch:  300 | Train bce loss: 0.01380 | Train score: 0.98181\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01039 | Train score: 0.98330\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01197 | Train score: 0.98278\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01552 | Train score: 0.97887\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01187 | Train score: 0.97928\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01013 | Train score: 0.98509\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.00909 | Train score: 0.98317\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01590 | Train score: 0.98014\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01266 | Train score: 0.98253\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.00940 | Train score: 0.98506\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.00959 | Train score: 0.98520\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.00895 | Train score: 0.98360\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   16 | Train bce loss: 0.01175 | Train score: 0.98230 | Val score: 0.99564\n",
      "==========\n",
      "=> EPOCH 17 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.00972 | Train score: 0.98306\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.00854 | Train score: 0.98417\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01119 | Train score: 0.98183\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01288 | Train score: 0.98045\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01257 | Train score: 0.98247\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01063 | Train score: 0.98334\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01265 | Train score: 0.98327\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.00924 | Train score: 0.98407\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.01313 | Train score: 0.98122\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01605 | Train score: 0.97982\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01318 | Train score: 0.98131\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.00956 | Train score: 0.98344\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01017 | Train score: 0.98392\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01157 | Train score: 0.98358\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   17 | Train bce loss: 0.01153 | Train score: 0.98265 | Val score: 0.99589\n",
      "==========\n",
      "=> EPOCH 18 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.00886 | Train score: 0.98417\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.02687 | Train score: 0.97515\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.00994 | Train score: 0.98444\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01121 | Train score: 0.98289\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01105 | Train score: 0.98432\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01185 | Train score: 0.98205\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01101 | Train score: 0.98348\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.00928 | Train score: 0.98496\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.00642 | Train score: 0.98606\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.01205 | Train score: 0.98198\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01262 | Train score: 0.98026\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.00695 | Train score: 0.98642\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01290 | Train score: 0.98238\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.00917 | Train score: 0.98538\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   18 | Train bce loss: 0.01126 | Train score: 0.98294 | Val score: 0.99598\n",
      "==========\n",
      "=> EPOCH 19 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01279 | Train score: 0.98181\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01016 | Train score: 0.98215\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.00979 | Train score: 0.98249\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01229 | Train score: 0.98253\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01005 | Train score: 0.98379\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.00924 | Train score: 0.98377\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.00874 | Train score: 0.98611\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01026 | Train score: 0.98372\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.00867 | Train score: 0.98443\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.00946 | Train score: 0.98489\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01117 | Train score: 0.98378\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01111 | Train score: 0.98232\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.01052 | Train score: 0.98233\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01379 | Train score: 0.98280\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   19 | Train bce loss: 0.01095 | Train score: 0.98335 | Val score: 0.92655\n",
      "==========\n",
      "=> EPOCH 20 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01120 | Train score: 0.98414\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01045 | Train score: 0.98383\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01587 | Train score: 0.98023\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01161 | Train score: 0.98274\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.00779 | Train score: 0.98561\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01116 | Train score: 0.98237\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01029 | Train score: 0.98494\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.00704 | Train score: 0.98644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.00775 | Train score: 0.98608\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.00915 | Train score: 0.98278\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01014 | Train score: 0.98453\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01017 | Train score: 0.98576\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.00887 | Train score: 0.98535\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01031 | Train score: 0.98421\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   20 | Train bce loss: 0.01088 | Train score: 0.98345 | Val score: 0.99582\n",
      "==========\n",
      "=> EPOCH 21 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01564 | Train score: 0.98044\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01222 | Train score: 0.98097\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01039 | Train score: 0.98542\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01183 | Train score: 0.98247\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.01094 | Train score: 0.98438\n",
      "   % Time:  471s | Batch:  600 | Train bce loss: 0.01115 | Train score: 0.98355\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.01027 | Train score: 0.98489\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.01127 | Train score: 0.98502\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.00809 | Train score: 0.98463\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.00909 | Train score: 0.98559\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.01317 | Train score: 0.98186\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01024 | Train score: 0.98370\n",
      "   % Time: 1019s | Batch: 1300 | Train bce loss: 0.00767 | Train score: 0.98621\n",
      "   % Time: 1097s | Batch: 1400 | Train bce loss: 0.01093 | Train score: 0.98292\n",
      "==========\n",
      "   % Time: 1181s | Epoch:   21 | Train bce loss: 0.01058 | Train score: 0.98385 | Val score: 0.99592\n",
      "==========\n",
      "=> EPOCH 22 with lr [0.001]\n",
      "   % Time:   79s | Batch:  100 | Train bce loss: 0.01145 | Train score: 0.98318\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01190 | Train score: 0.97955\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.01282 | Train score: 0.98266\n",
      "   % Time:  314s | Batch:  400 | Train bce loss: 0.01369 | Train score: 0.98357\n",
      "   % Time:  392s | Batch:  500 | Train bce loss: 0.00940 | Train score: 0.98500\n",
      "   % Time:  470s | Batch:  600 | Train bce loss: 0.01151 | Train score: 0.98399\n",
      "   % Time:  549s | Batch:  700 | Train bce loss: 0.00836 | Train score: 0.98670\n",
      "   % Time:  627s | Batch:  800 | Train bce loss: 0.00917 | Train score: 0.98441\n",
      "   % Time:  706s | Batch:  900 | Train bce loss: 0.00897 | Train score: 0.98582\n",
      "   % Time:  784s | Batch: 1000 | Train bce loss: 0.00920 | Train score: 0.98577\n",
      "   % Time:  862s | Batch: 1100 | Train bce loss: 0.00769 | Train score: 0.98603\n",
      "   % Time:  941s | Batch: 1200 | Train bce loss: 0.01052 | Train score: 0.98443\n",
      "   % Time:  157s | Batch:  200 | Train bce loss: 0.01149 | Train score: 0.98357\n",
      "   % Time:  235s | Batch:  300 | Train bce loss: 0.00957 | Train score: 0.98562\n"
     ]
    }
   ],
   "source": [
    "if args.train:\n",
    "    for epoch in range(1, 42):\n",
    "        scheduler.step()\n",
    "        print(\"=> EPOCH {} with lr {}\".format(epoch, scheduler.get_lr()))\n",
    "        init_time = time.time()\n",
    "        train_bce_loss, train_score = train(train_loader, model, optimizer)\n",
    "        val_score = validate(val_loader, model)\n",
    "        print(\"=\"*10)\n",
    "        print(\"   % Time: {:4.0f}s | Epoch: {:4} | Train bce loss: {:.5f} \"\n",
    "              \"| Train score: {:.5f} | Val score: {:.5f}\"\n",
    "              .format(time.time()-init_time, epoch, train_bce_loss,\n",
    "                      train_score, val_score))\n",
    "        print(\"=\"*10)\n",
    "        save_model(model, epoch, val_score)\n",
    "else:\n",
    "    load_model(model, args.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-22T05:00:42.346Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if args.test:\n",
    "    test_dataset = CarDataset(args.test_path, transform=[], mode='test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "    list_rle = test(test_loader, model)\n",
    "    \n",
    "#    df = pd.DataFrame({\"img\": test_dataset.img_names, \"rle_mask\": list_rle})\n",
    "#    submiss_path = os.path.join(args.intermediate_path, \"submission.csv\")\n",
    "#    df.to_csv(submiss_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pydata)",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
