{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:24.071908Z",
     "start_time": "2017-09-25T14:07:24.065634Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:24.676789Z",
     "start_time": "2017-09-25T14:07:24.395196Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:24.931631Z",
     "start_time": "2017-09-25T14:07:24.739710Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:25.026250Z",
     "start_time": "2017-09-25T14:07:24.986278Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'train_path': '../data/train4320/',\n",
    "    'train_masks_path': '../data/train4320_masks/',\n",
    "    'val_path': '../data/val768/',\n",
    "    'val_masks_path': '../data/val768_masks/',\n",
    "    'test_path': '../data/test_hq/',\n",
    "    'split_data': False,\n",
    "    'batch_size': 3,\n",
    "    'log_every': 10,\n",
    "    'train': False,\n",
    "    'model_name': '',\n",
    "    'test': False,\n",
    "    'seed': 20170915,\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "args.intermediate_path = os.path.join('../intermediate/',\n",
    "#                                     str(args.seed))\n",
    "                                      'output/')  \n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.mkdir(args.intermediate_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:25.300681Z",
     "start_time": "2017-09-25T14:07:25.236272Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if args.split_data:\n",
    "    # !mogrify -format png *.gif\n",
    "    if not os.path.isdir(args.train_path):\n",
    "        os.mkdir(args.train_path)\n",
    "    if not os.path.isdir(args.train_masks_path):\n",
    "        os.mkdir(args.train_masks_path)\n",
    "    if not os.path.isdir(args.val_path):\n",
    "        os.mkdir(args.val_path)\n",
    "    if not os.path.isdir(args.val_masks_path):\n",
    "        os.mkdir(args.val_masks_path)\n",
    "    files = sorted([x.split('/')[-1]\n",
    "                    for x in glob.glob('../data/train_hq/*.jpg')])\n",
    "    random.seed(args.seed)\n",
    "    random.shuffle(files)\n",
    "    for filename in files[:4320]:\n",
    "        image = cv2.imread('../data/train_hq/' + filename)\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        cv2.imwrite(os.path.join(args.train_path, filename), image)\n",
    "        mask_filename = '../data/train_masks/'+filename.replace('.jpg',\n",
    "                                                                '_mask.png')\n",
    "        shutil.copy2(mask_filename, args.train_masks_path)\n",
    "    for filename in files[4320:]:\n",
    "        image = cv2.imread('../data/train_hq/' + filename)\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "        cv2.imwrite(os.path.join(args.val_path, filename), image)\n",
    "        mask_filename = '../data/train_masks/'+filename.replace('.jpg',\n",
    "                                                                '_mask.png')\n",
    "        shutil.copy2(mask_filename, args.val_masks_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:25.619731Z",
     "start_time": "2017-09-25T14:07:25.608094Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvBnRelu2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        padding = kernel_size//2 * dilation\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              dilation=dilation, padding=padding, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels, eps=1e-4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            o = self.bn(o)\n",
    "        return F.relu(o, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:25.790457Z",
     "start_time": "2017-09-25T14:07:25.775134Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            ConvBnRelu2d(in_channels, out_channels, kernel_size),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.encode(x)\n",
    "        o = F.max_pool2d(e, kernel_size=2, stride=2)\n",
    "        return e, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:25.986991Z",
     "start_time": "2017-09-25T14:07:25.951751Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, en_channels, in_channels, out_channels,\n",
    "                 kernel_size=3):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            ConvBnRelu2d(en_channels+in_channels, out_channels, kernel_size),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size))\n",
    "\n",
    "    def forward(self, e, x):\n",
    "        N,C,H,W = e.size()\n",
    "        x = F.upsample(x, size=(H,W), mode='bilinear')\n",
    "        x = torch.cat([e, x], dim=1)\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:26.218373Z",
     "start_time": "2017-09-25T14:07:26.122983Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UNet1024(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_shape):\n",
    "        super(UNet1024, self).__init__()\n",
    "        C,H,W = in_shape\n",
    "\n",
    "        # 1024\n",
    "        self.down1 = StackEncoder(  C,  24)  # 512\n",
    "        self.down2 = StackEncoder( 24,  64)  # 256\n",
    "        self.down3 = StackEncoder( 64, 128)  # 128\n",
    "        self.down4 = StackEncoder(128, 256)  # 64\n",
    "        self.down5 = StackEncoder(256, 512)  # 32\n",
    "        self.down6 = StackEncoder(512, 768)  # 16\n",
    "\n",
    "        self.center = ConvBnRelu2d(768, 768)\n",
    "\n",
    "        # 16\n",
    "        self.up6 = StackDecoder(768, 768, 512)  # 32\n",
    "        self.up5 = StackDecoder(512, 512, 256)  # 64\n",
    "        self.up4 = StackDecoder(256, 256, 128)  # 128\n",
    "        self.up3 = StackDecoder(128, 128,  64)  # 256\n",
    "        self.up2 = StackDecoder( 64,  64,  24)  # 512\n",
    "        self.up1 = StackDecoder( 24,  24,  24)  # 1024\n",
    "        \n",
    "        self.mask = nn.Conv2d(24, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1, o = self.down1(x)\n",
    "        e2, o = self.down2(o)\n",
    "        e3, o = self.down3(o)\n",
    "        e4, o = self.down4(o)\n",
    "        e5, o = self.down5(o)\n",
    "        e6, o = self.down6(o)\n",
    "\n",
    "        o = self.center(o)\n",
    "        \n",
    "        o = self.up6(e6, o)\n",
    "        o = self.up5(e5, o)\n",
    "        o = self.up4(e4, o)\n",
    "        o = self.up3(e3, o)\n",
    "        o = self.up2(e2, o)\n",
    "        o = self.up1(e1, o)\n",
    "\n",
    "        o = self.mask(o)\n",
    "        o = F.upsample(o, size=(1280,1918), mode='bilinear')\n",
    "        return torch.squeeze(o, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:26.495897Z",
     "start_time": "2017-09-25T14:07:26.444870Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_score(probs, target, weight=None, use_mask=True, threshold=0.5):\n",
    "    if use_mask:\n",
    "        probs = (probs > threshold).float()\n",
    "    N     = target.size(0)\n",
    "    if weight is None:\n",
    "        w = Variable(torch.ones(target.size()).cuda()).view(N, -1)\n",
    "    else:\n",
    "        w = weight.view(N, -1)\n",
    "    w2    = w*w\n",
    "    m1    = probs.view(N, -1)\n",
    "    m2    = target.view(N, -1)\n",
    "    score = (2*(w2*m1*m2).sum(dim=1) + 1) / ((w2*m1).sum(dim=1)\n",
    "                                             + (w2*m2).sum(dim=1) + 1)\n",
    "    \n",
    "    return score.sum()/N\n",
    "\n",
    "\n",
    "def dice_loss(logits, target, weight=None):\n",
    "    probs = F.sigmoid(logits)\n",
    "    loss  = 1 - dice_score(probs, target, weight, use_mask=False)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def criterion(logits, target):\n",
    "    N,H,W = target.size()\n",
    "    a = F.avg_pool2d(target, kernel_size=41, stride=1, padding=20)\n",
    "    boundary = (a.ge(0.01) * a.le(0.99)).float()\n",
    "    weight = Variable(torch.ones(a.size()).cuda())\n",
    "    w0 = weight.sum()\n",
    "    weight = weight + 2*boundary\n",
    "    w1 = weight.sum()\n",
    "    weight = weight*w0/w1\n",
    "        \n",
    "    return (F.binary_cross_entropy_with_logits(logits, target, weight)\n",
    "            + dice_loss(logits, target, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:26.647066Z",
     "start_time": "2017-09-25T14:07:26.623010Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    image = image.transpose((2,0,1)).astype(np.float32)  # HWC -> CHW\n",
    "    tensor = torch.from_numpy(image)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def label_to_tensor(label, threshold=0.5):\n",
    "    label  = (label>threshold).astype(np.float32)\n",
    "    tensor = torch.from_numpy(label)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:26.892089Z",
     "start_time": "2017-09-25T14:07:26.794500Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CarDataset(Dataset):\n",
    "\n",
    "    def __init__(self, image_path, mask_path='', transform=[], mode='train'):\n",
    "        super(CarDataset, self).__init__()\n",
    "        self.img_names = sorted([x.split('/')[-1]\n",
    "                                 for x in glob.glob(image_path + '/*.jpg')])\n",
    "        self.img_path  = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.transform = transform\n",
    "        self.mode      = mode\n",
    "\n",
    "    def get_image(self, index):\n",
    "        name  = self.img_names[index]\n",
    "        file  = os.path.join(self.img_path, name)\n",
    "        img   = cv2.imread(file)\n",
    "#        img = cv2.resize(img, (1024, 1024))\n",
    "        image = img / 255\n",
    "        return image, name\n",
    "    \n",
    "    def get_label(self, name):\n",
    "        name = name.replace('.jpg', '_mask.png')\n",
    "        file = os.path.join(self.mask_path, name)\n",
    "        mask = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        label = mask / 255\n",
    "        return label\n",
    "\n",
    "    def get_train_item(self, index):\n",
    "        image, name = self.get_image(index)\n",
    "        label = self.get_label(name)\n",
    "        image = image_to_tensor(image)\n",
    "        label = label_to_tensor(label)\n",
    "        return image, label\n",
    "\n",
    "    def get_test_item(self, index):\n",
    "        image, name = self.get_image(index)\n",
    "        image = image_to_tensor(image)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            return self.get_train_item(index)\n",
    "        elif self.mode == 'test':\n",
    "            return self.get_test_item(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:27.048969Z",
     "start_time": "2017-09-25T14:07:26.996481Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer):\n",
    "    num_grad_acc = 16 // args.batch_size\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    init_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    for i, (inputt, target) in enumerate(train_loader, 1):\n",
    "        inputt = inputt.cuda()\n",
    "        target = target.cuda()\n",
    "        inputt = Variable(inputt)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        output = model(inputt)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        if i % num_grad_acc == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        train_loss += loss.data[0] * inputt.size(0)\n",
    "        if i % args.log_every == 0:\n",
    "            print(\"   % Time: {:4.0f}s | Batch: {:3} | Train loss: {:.4f}\"\n",
    "                  .format(time.time()-init_time, i, loss.data[0]))\n",
    "    return train_loss / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:27.222467Z",
     "start_time": "2017-09-25T14:07:27.189298Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model):\n",
    "    model.eval()\n",
    "    val_score = 0\n",
    "    for i, (inputt, target) in enumerate(val_loader, 1):\n",
    "        inputt = inputt.cuda()\n",
    "        target = target.cuda()\n",
    "        inputt = Variable(inputt, volatile=True)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        output = model(inputt)\n",
    "        score = dice_score(F.sigmoid(output), target)\n",
    "        val_score += score.data[0] * inputt.size(0)\n",
    "    return val_score / len(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:27.455384Z",
     "start_time": "2017-09-25T14:07:27.445115Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, epoch, score):\n",
    "    model_file = os.path.join(args.intermediate_path,\n",
    "                              \"model_{}_epoch{}_score{:.5f}.pth\"\n",
    "                              .format(args.seed, epoch, score))\n",
    "    torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:27.645170Z",
     "start_time": "2017-09-25T14:07:27.638584Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(model, model_name):\n",
    "    model_path = os.path.join(args.intermediate_path, model_name)\n",
    "    assert os.path.isfile(model_path), 'Error: no model found!'\n",
    "    model_state = torch.load(model_path)\n",
    "    model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:27.849052Z",
     "start_time": "2017-09-25T14:07:27.841481Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rle_encode(mask_image):\n",
    "    pixels = mask_image.flatten()\n",
    "    # We avoid issues with '1' at the start or end (at the corners of \n",
    "    # the original image) by setting those pixels to '0' explicitly.\n",
    "    # We do not expect these to be non-zero for an accurate mask, \n",
    "    # so this should not harm the score.\n",
    "    pixels[0] = 0\n",
    "    pixels[-1] = 0\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:28.546860Z",
     "start_time": "2017-09-25T14:07:28.533553Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_loader, model, threshold=0.5):\n",
    "    model.eval()\n",
    "    init_time = time.time()\n",
    "    list_rle = []\n",
    "    for i, imgs in enumerate(test_loader, 1):\n",
    "        imgs = imgs.cuda()\n",
    "        imgs = Variable(imgs, volatile= True)\n",
    "        outputs = model(imgs)\n",
    "        outputs = outputs > threshold\n",
    "        for j in range(outputs.size(0)):\n",
    "            rle = rle_encode(outputs[j, :, :].data.cpu().numpy())\n",
    "            list_rle.append(' '.join(str(x) for x in rle))\n",
    "            \n",
    "        if i % args.log_every == 0:\n",
    "            print(\"   % Time: {:4.0f}s | Image: {:6d} / {}\"\n",
    "                  .format(time.time()-init_time, i*args.batch_size,\n",
    "                          len(test_loader.dataset)))\n",
    "    return list_rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:29.480139Z",
     "start_time": "2017-09-25T14:07:29.463977Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CarDataset(args.train_path, args.train_masks_path,\n",
    "                           transform=[], mode='train')\n",
    "train_loader  = DataLoader(train_dataset, args.batch_size, shuffle=True,\n",
    "                           num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:29.955108Z",
     "start_time": "2017-09-25T14:07:29.942562Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_dataset = CarDataset(args.val_path, args.val_masks_path,\n",
    "                         transform=[], mode='train')\n",
    "val_loader  = DataLoader(val_dataset, args.batch_size, num_workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:07:31.918195Z",
     "start_time": "2017-09-25T14:07:30.516686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = UNet1024((3, 1024, 1024))\n",
    "model.cuda()\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,\n",
    "#                      weight_decay=0.0005)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-25T14:43:19.256802Z",
     "start_time": "2017-09-25T14:42:34.947200Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "    load_model(model, 'model_unet_38.pth')\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    for i, (inputt, _) in enumerate(val_loader, 1):\n",
    "        inputt = inputt.cuda()\n",
    "        inputt = Variable(inputt, volatile=True)\n",
    "        output = F.sigmoid(model(inputt)) * 255\n",
    "        output_list.append(output.data.cpu().numpy().astype(np.uint8))\n",
    "    val_unet_38 = np.concatenate(output_list)\n",
    "    with open('../intermediate/output/val_unet_38.pkl', 'wb') as f:\n",
    "        pickle.dump(val_unet_38, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-21T13:48:39.029119Z",
     "start_time": "2017-09-21T13:31:50.362199Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> EPOCH 1 with lr [1e-05]\n",
      "   % Time:    7s | Batch:  10 | Train loss: 0.0217\n",
      "   % Time:   14s | Batch:  20 | Train loss: 0.0225\n",
      "   % Time:   21s | Batch:  30 | Train loss: 0.0216\n",
      "   % Time:   27s | Batch:  40 | Train loss: 0.0207\n",
      "   % Time:   34s | Batch:  50 | Train loss: 0.0260\n",
      "   % Time:   41s | Batch:  60 | Train loss: 0.0187\n",
      "   % Time:   47s | Batch:  70 | Train loss: 0.0212\n",
      "   % Time:   54s | Batch:  80 | Train loss: 0.0258\n",
      "   % Time:   61s | Batch:  90 | Train loss: 0.0205\n",
      "   % Time:   67s | Batch: 100 | Train loss: 0.0246\n",
      "   % Time:   74s | Batch: 110 | Train loss: 0.0255\n",
      "   % Time:   81s | Batch: 120 | Train loss: 0.0208\n",
      "   % Time:   87s | Batch: 130 | Train loss: 0.0242\n",
      "   % Time:   94s | Batch: 140 | Train loss: 0.0234\n",
      "   % Time:  101s | Batch: 150 | Train loss: 0.0223\n",
      "   % Time:  107s | Batch: 160 | Train loss: 0.0212\n",
      "   % Time:  114s | Batch: 170 | Train loss: 0.0173\n",
      "   % Time:  121s | Batch: 180 | Train loss: 0.0317\n",
      "   % Time:  127s | Batch: 190 | Train loss: 0.0220\n",
      "   % Time:  134s | Batch: 200 | Train loss: 0.0239\n",
      "   % Time:  141s | Batch: 210 | Train loss: 0.0201\n",
      "   % Time:  148s | Batch: 220 | Train loss: 0.0158\n",
      "   % Time:  154s | Batch: 230 | Train loss: 0.0191\n",
      "   % Time:  161s | Batch: 240 | Train loss: 0.0193\n",
      "   % Time:  168s | Batch: 250 | Train loss: 0.0342\n",
      "   % Time:  174s | Batch: 260 | Train loss: 0.0204\n",
      "   % Time:  181s | Batch: 270 | Train loss: 0.0219\n",
      "   % Time:  188s | Batch: 280 | Train loss: 0.0198\n",
      "   % Time:  194s | Batch: 290 | Train loss: 0.0212\n",
      "   % Time:  201s | Batch: 300 | Train loss: 0.0218\n",
      "   % Time:  208s | Batch: 310 | Train loss: 0.0183\n",
      "   % Time:  215s | Batch: 320 | Train loss: 0.0201\n",
      "   % Time:  221s | Batch: 330 | Train loss: 0.0177\n",
      "   % Time:  228s | Batch: 340 | Train loss: 0.0228\n",
      "   % Time:  235s | Batch: 350 | Train loss: 0.0225\n",
      "   % Time:  241s | Batch: 360 | Train loss: 0.0230\n",
      "   % Time:  248s | Batch: 370 | Train loss: 0.0219\n",
      "   % Time:  255s | Batch: 380 | Train loss: 0.0234\n",
      "   % Time:  261s | Batch: 390 | Train loss: 0.0190\n",
      "   % Time:  268s | Batch: 400 | Train loss: 0.0221\n",
      "   % Time:  275s | Batch: 410 | Train loss: 0.0193\n",
      "   % Time:  282s | Batch: 420 | Train loss: 0.0196\n",
      "   % Time:  288s | Batch: 430 | Train loss: 0.0227\n",
      "   % Time:  295s | Batch: 440 | Train loss: 0.0215\n",
      "   % Time:  302s | Batch: 450 | Train loss: 0.0195\n",
      "   % Time:  308s | Batch: 460 | Train loss: 0.0198\n",
      "   % Time:  315s | Batch: 470 | Train loss: 0.0192\n",
      "   % Time:  322s | Batch: 480 | Train loss: 0.0172\n",
      "   % Time:  329s | Batch: 490 | Train loss: 0.0223\n",
      "   % Time:  335s | Batch: 500 | Train loss: 0.0193\n",
      "   % Time:  342s | Batch: 510 | Train loss: 0.0219\n",
      "   % Time:  349s | Batch: 520 | Train loss: 0.0204\n",
      "   % Time:  355s | Batch: 530 | Train loss: 0.0210\n",
      "   % Time:  362s | Batch: 540 | Train loss: 0.0281\n",
      "   % Time:  369s | Batch: 550 | Train loss: 0.0245\n",
      "   % Time:  376s | Batch: 560 | Train loss: 0.0245\n",
      "   % Time:  382s | Batch: 570 | Train loss: 0.0212\n",
      "   % Time:  389s | Batch: 580 | Train loss: 0.0200\n",
      "   % Time:  396s | Batch: 590 | Train loss: 0.0254\n",
      "   % Time:  402s | Batch: 600 | Train loss: 0.0217\n",
      "   % Time:  409s | Batch: 610 | Train loss: 0.0218\n",
      "   % Time:  416s | Batch: 620 | Train loss: 0.0245\n",
      "   % Time:  422s | Batch: 630 | Train loss: 0.0204\n",
      "   % Time:  429s | Batch: 640 | Train loss: 0.0207\n",
      "   % Time:  436s | Batch: 650 | Train loss: 0.0231\n",
      "   % Time:  443s | Batch: 660 | Train loss: 0.0221\n",
      "   % Time:  449s | Batch: 670 | Train loss: 0.0191\n",
      "   % Time:  456s | Batch: 680 | Train loss: 0.0175\n",
      "   % Time:  463s | Batch: 690 | Train loss: 0.0240\n",
      "   % Time:  469s | Batch: 700 | Train loss: 0.0195\n",
      "   % Time:  476s | Batch: 710 | Train loss: 0.0235\n",
      "   % Time:  483s | Batch: 720 | Train loss: 0.0195\n",
      "   % Time:  490s | Batch: 730 | Train loss: 0.0235\n",
      "   % Time:  496s | Batch: 740 | Train loss: 0.0190\n",
      "   % Time:  503s | Batch: 750 | Train loss: 0.0208\n",
      "   % Time:  510s | Batch: 760 | Train loss: 0.0198\n",
      "   % Time:  516s | Batch: 770 | Train loss: 0.0217\n",
      "   % Time:  523s | Batch: 780 | Train loss: 0.0172\n",
      "   % Time:  530s | Batch: 790 | Train loss: 0.0234\n",
      "   % Time:  536s | Batch: 800 | Train loss: 0.0214\n",
      "   % Time:  543s | Batch: 810 | Train loss: 0.0208\n",
      "   % Time:  550s | Batch: 820 | Train loss: 0.0205\n",
      "   % Time:  557s | Batch: 830 | Train loss: 0.0209\n",
      "   % Time:  563s | Batch: 840 | Train loss: 0.0214\n",
      "   % Time:  570s | Batch: 850 | Train loss: 0.0187\n",
      "   % Time:  577s | Batch: 860 | Train loss: 0.0177\n",
      "   % Time:  583s | Batch: 870 | Train loss: 0.0241\n",
      "   % Time:  590s | Batch: 880 | Train loss: 0.0190\n",
      "   % Time:  597s | Batch: 890 | Train loss: 0.0225\n",
      "   % Time:  604s | Batch: 900 | Train loss: 0.0236\n",
      "   % Time:  610s | Batch: 910 | Train loss: 0.0225\n",
      "   % Time:  617s | Batch: 920 | Train loss: 0.0184\n",
      "   % Time:  624s | Batch: 930 | Train loss: 0.0223\n",
      "   % Time:  630s | Batch: 940 | Train loss: 0.0198\n",
      "   % Time:  637s | Batch: 950 | Train loss: 0.0216\n",
      "   % Time:  644s | Batch: 960 | Train loss: 0.0242\n",
      "   % Time:  651s | Batch: 970 | Train loss: 0.0204\n",
      "   % Time:  657s | Batch: 980 | Train loss: 0.0209\n",
      "   % Time:  664s | Batch: 990 | Train loss: 0.0251\n",
      "   % Time:  671s | Batch: 1000 | Train loss: 0.0204\n",
      "   % Time:  677s | Batch: 1010 | Train loss: 0.0243\n",
      "   % Time:  684s | Batch: 1020 | Train loss: 0.0226\n",
      "   % Time:  691s | Batch: 1030 | Train loss: 0.0201\n",
      "   % Time:  697s | Batch: 1040 | Train loss: 0.0207\n",
      "   % Time:  704s | Batch: 1050 | Train loss: 0.0202\n",
      "   % Time:  711s | Batch: 1060 | Train loss: 0.0196\n",
      "   % Time:  718s | Batch: 1070 | Train loss: 0.0260\n",
      "   % Time:  724s | Batch: 1080 | Train loss: 0.0301\n",
      "   % Time:  731s | Batch: 1090 | Train loss: 0.0202\n",
      "   % Time:  738s | Batch: 1100 | Train loss: 0.0236\n",
      "   % Time:  744s | Batch: 1110 | Train loss: 0.0211\n",
      "   % Time:  751s | Batch: 1120 | Train loss: 0.0183\n",
      "   % Time:  758s | Batch: 1130 | Train loss: 0.0219\n",
      "   % Time:  765s | Batch: 1140 | Train loss: 0.0204\n",
      "   % Time:  771s | Batch: 1150 | Train loss: 0.0244\n",
      "   % Time:  778s | Batch: 1160 | Train loss: 0.0200\n",
      "   % Time:  785s | Batch: 1170 | Train loss: 0.0224\n",
      "   % Time:  791s | Batch: 1180 | Train loss: 0.0247\n",
      "   % Time:  798s | Batch: 1190 | Train loss: 0.0192\n",
      "   % Time:  805s | Batch: 1200 | Train loss: 0.0251\n",
      "   % Time:  811s | Batch: 1210 | Train loss: 0.0245\n",
      "   % Time:  818s | Batch: 1220 | Train loss: 0.0263\n",
      "   % Time:  825s | Batch: 1230 | Train loss: 0.0219\n",
      "   % Time:  832s | Batch: 1240 | Train loss: 0.0232\n",
      "   % Time:  838s | Batch: 1250 | Train loss: 0.0210\n",
      "   % Time:  845s | Batch: 1260 | Train loss: 0.0222\n",
      "   % Time:  852s | Batch: 1270 | Train loss: 0.0196\n",
      "   % Time:  858s | Batch: 1280 | Train loss: 0.0193\n",
      "   % Time:  865s | Batch: 1290 | Train loss: 0.0241\n",
      "   % Time:  872s | Batch: 1300 | Train loss: 0.0246\n",
      "   % Time:  879s | Batch: 1310 | Train loss: 0.0219\n",
      "   % Time:  885s | Batch: 1320 | Train loss: 0.0200\n",
      "   % Time:  892s | Batch: 1330 | Train loss: 0.0223\n",
      "   % Time:  899s | Batch: 1340 | Train loss: 0.0200\n",
      "   % Time:  905s | Batch: 1350 | Train loss: 0.0186\n",
      "   % Time:  912s | Batch: 1360 | Train loss: 0.0216\n",
      "   % Time:  919s | Batch: 1370 | Train loss: 0.0242\n",
      "   % Time:  926s | Batch: 1380 | Train loss: 0.0205\n",
      "   % Time:  932s | Batch: 1390 | Train loss: 0.0220\n",
      "   % Time:  939s | Batch: 1400 | Train loss: 0.0220\n",
      "   % Time:  946s | Batch: 1410 | Train loss: 0.0238\n",
      "   % Time:  952s | Batch: 1420 | Train loss: 0.0197\n",
      "   % Time:  959s | Batch: 1430 | Train loss: 0.0262\n",
      "   % Time:  966s | Batch: 1440 | Train loss: 0.0193\n",
      "==========\n",
      "   % Epoch: 1 | Time: 1008s | Train loss: 0.02167 | Val score: 0.99697\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "if args.train:\n",
    "    load_model(model, 'model_20170915_epoch30_score0.9969.pth')\n",
    "    torch.manual_seed(35)\n",
    "    for epoch in range(1,2):\n",
    "        scheduler.step()\n",
    "        print(\"=> EPOCH {} with lr {}\".format(epoch, scheduler.get_lr()))\n",
    "        init_time = time.time()\n",
    "        train_loss = train(train_loader, model, optimizer)\n",
    "        val_score = validate(val_loader, model)\n",
    "        print(\"=\"*10)\n",
    "        print(\"   % Epoch: {} | Time: {:4.0f}s | \"\n",
    "              \"Train loss: {:.5f} | Val score: {:.5f}\"\n",
    "              .format(epoch, time.time()-init_time, train_loss, val_score))\n",
    "        print(\"=\"*10)\n",
    "        save_model(model, epoch, val_score)\n",
    "else:\n",
    "    load_model(model, args.model_name)\n",
    "    val_score = validate(val_loader, model)\n",
    "    print(val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-21T13:48:39.041654Z",
     "start_time": "2017-09-21T13:48:39.034270Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if args.test:\n",
    "    test_dataset = CarDataset(args.test_path, transform=[], mode='test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size)\n",
    "    list_rle = test(test_loader, model)\n",
    "    \n",
    "    df = pd.DataFrame({\"img\": test_dataset.img_names, \"rle_mask\": list_rle})\n",
    "    submiss_path = os.path.join(args.intermediate_path, \"submission.csv\")\n",
    "    df.to_csv(submiss_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pydata)",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
