{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import PIL\n",
    "import cv2\n",
    "import math\n",
    "import collections\n",
    "import types\n",
    "import numbers\n",
    "import inspect\n",
    "import shutil\n",
    "import dill\n",
    "from timeit import default_timer as timer\n",
    "# std libs\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import glob\n",
    "import sys\n",
    "#from time import sleep\n",
    "from distutils.dir_util import copy_tree\n",
    "import zipfile\n",
    "import zlib\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "from skimage import io\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = {\n",
    "    'train_path': '../data/train/',\n",
    "    'train_hq_path': '../data/train_hq/',\n",
    "    'train_masks_path': '../data/train_masks/',\n",
    "    'train_makes_file': '../data/train_masks.csv',\n",
    "    'intermediate_path': '../intermediate/',\n",
    "    'train_len': 385,\n",
    "    'train_skip': 91,\n",
    "    'val_len': 64,\n",
    "    'offset': 803,\n",
    "    'batch_size': 256,\n",
    "    'hidden_size': 256,\n",
    "    'log_every': 10,\n",
    "    'read_from_file': False,\n",
    "    'train': True,\n",
    "    'model_name': '',\n",
    "    'test': False,\n",
    "    'cuda': True,\n",
    "    'seed': 20170915,\n",
    "}\n",
    "args = argparse.Namespace(**parser)\n",
    "\n",
    "args.cuda = args.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "args.intermediate_path = os.path.join(args.intermediate_path, str(args.seed))\n",
    "if not os.path.isdir(args.intermediate_path):\n",
    "    os.makedir(args.intermediate_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnRelu2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding, bias=False)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels, eps=1e-4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            o = self.bn(o)\n",
    "        return self.relu(o)\n",
    "\n",
    "\n",
    "    def merge_bn(self):  # for faster inference\n",
    "        if self.bn is None:\n",
    "            return\n",
    "        \n",
    "        conv_weight     = self.conv.weight.data\n",
    "        bn_weight       = self.bn.weight.data\n",
    "        bn_bias         = self.bn.bias.data\n",
    "        bn_running_mean = self.bn.running_mean\n",
    "        bn_running_var  = self.bn.running_var\n",
    "        bn_eps          = self.bn.eps\n",
    "\n",
    "        N,C,H,W = conv_weight.size()\n",
    "        std = torch.sqrt(bn_running_var+bn_eps)\n",
    "        std_bn_weight = (bn_weight/std).repeat(C*H*W,1).t().contiguous().view(N,C,H,W)\n",
    "        conv_weight_hat = std_bn_weight*conv_weight\n",
    "        conv_bias_hat   = bn_bias - (bn_weight/std)*bn_running_mean\n",
    "        \n",
    "        self.conv = nn.Conv2d(self.conv.in_channels, self.conv.out_channels, self.conv.kernel_size,\n",
    "                              padding=self.conv.padding, bias=True)\n",
    "        self.conv.weight.data = conv_weight_hat\n",
    "        self.conv.bias.data   = conv_bias_hat\n",
    "        self.bn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackEncoder (nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            ConvBnRelu2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size, padding=padding),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.encode(x)\n",
    "        o = F.max_pool2d(e, kernel_size=2, stride=2)\n",
    "        return e, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackDecoder (nn.Module):\n",
    "    def __init__(self, en_channels, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            ConvBnRelu2d(en_channels+in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            ConvBnRelu2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "        )\n",
    "\n",
    "    def forward(self, e, x):\n",
    "        N,C,H,W = e.size()\n",
    "        x = F.upsample(x, size=(H,W), mode='bilinear')\n",
    "        x = torch.cat([e, x], dim=1)\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet1024(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super(UNet1024, self).__init__()\n",
    "        C,H,W = in_shape\n",
    "\n",
    "        # 1024\n",
    "        self.down1 = StackEncoder(  C,  24, kernel_size=3)  # 512\n",
    "        self.down2 = StackEncoder( 24,  64, kernel_size=3)  # 256\n",
    "        self.down3 = StackEncoder( 64, 128, kernel_size=3)  # 128\n",
    "        self.down4 = StackEncoder(128, 256, kernel_size=3)  # 64\n",
    "        self.down5 = StackEncoder(256, 512, kernel_size=3)  # 32\n",
    "        self.down6 = StackEncoder(512, 768, kernel_size=3)  # 16\n",
    "\n",
    "        self.center = ConvBnRelu2d(768, 768, kernel_size=3, padding=1)\n",
    "\n",
    "        # 16\n",
    "        self.up6 = StackDecoder(768, 768, 512, kernel_size=3)  # 32\n",
    "        self.up5 = StackDecoder(512, 512, 256, kernel_size=3)  # 64\n",
    "        self.up4 = StackDecoder(256, 256, 128, kernel_size=3)  # 128\n",
    "        self.up3 = StackDecoder(128, 128,  64, kernel_size=3)  # 256\n",
    "        self.up2 = StackDecoder( 64,  64,  24, kernel_size=3)  # 512\n",
    "        self.up1 = StackDecoder( 24,  24,  24, kernel_size=3)  # 1024\n",
    "        \n",
    "        self.mask = nn.Conv2d(24, 1, kernel_size=1, padding=0, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1, o = self.down1(x)\n",
    "        e2, o = self.down2(o)\n",
    "        e3, o = self.down3(o)\n",
    "        e4, o = self.down4(o)\n",
    "        e5, o = self.down5(o)\n",
    "        e6, o = self.down6(o)\n",
    "\n",
    "        o = self.center(o)\n",
    "        \n",
    "        o = self.up6(e6, o)\n",
    "        o = self.up5(e5, o)\n",
    "        o = self.up4(e4, o)\n",
    "        o = self.up3(e3, o)\n",
    "        o = self.up2(e2, o)\n",
    "        o = self.up1(e1, o)\n",
    "\n",
    "        o = self.mask(o)\n",
    "        o = torch.squeeze(o, dim=1)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pydata)",
   "language": "python",
   "name": "pydata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
